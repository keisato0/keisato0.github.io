# 中心極限定理について話そうか

## 登場人物

ご隠居：高齢であること以外の社会的属性は不明。語尾に「〜なんです」とつける癖があるため、はっぴいえんどファンではないかといわれているんです。

熊さん：ご隠居に質問をする人。いっさいの社会的属性が不明。

## 中心極限定理とは

熊さん：中心極限定理ってなんですか。

ご隠居：中心極限定理の前提は、母集団に確率変数が存在するということなんです。

熊さん：確率的に変動するなんらかの値があり、その平均や分散などを知りたいということですね。

ご隠居：全くそのとおりなんです。ここではその母平均を$\mu$、母分散を$\sigma^2$であると表記しましょう。しかし直接母集団の確率変数のデータをあつめて、計算することが困難な場合が多いんです、現実には。

熊さん：データをあつめて...? それで私もデータをあつめて...? 母集団が大きすぎたりすると難しいでしょうね。

ご隠居：そうなんです。それでどうするかというと、母集団をランダム・サンプリングして、サンプルをとるんです。そしてサンプル内の平均や分散を計算することで、母平均や母分散を推測しようとするんです。

熊さん：まあ感覚的にはわかりますわね。ランダム・サンプリングされていれば、サンプルの構成と母集団の構成の共通性は高くなるでしょうから。しかしランダム性が確保されているとはいえ、なぜ限られたサンプルから母集団の確率分布を推測できるんでしょうか？

ご隠居：感覚的にわかる、その感じが重要なんです。それこそ感覚的にいえば、サンプル内平均と母平均は一致しそうな気がしませんか...?

熊さん：そうかもしれません。しかし、現実にはサンプルは1回しかとれないことが多いでしょう。そこでたまたま、偏りの大きいサンプルを引いてしまい、サンプル内平均が母平均と比べて大きすぎたり小さすぎたりすることもあるのでは...?

ご隠居：まったくそのとおりなんです。なのでここでは、サンプリングを何回も行える、という仮想的な前提を導入しましょう。

熊さん：何回もサンプリングを行い、サンプル内平均を毎回毎回算出して並べてみれば、平均的にはサンプル内平均の値は母平均に近づきそうですね。  
改めて言い直してみると、まずサンプル内平均の大きさ自体が、サンプルを引くときの偏りによって確率的に変動するわけです。  
しかしその偏りというのは、母平均を基準として大きい場合と小さい場合があり、何回もサンプリングするとその両ケースが打ち消し合うために、平均的には母平均$\mu$に近づいていくんです。

ご隠居：語尾が似てきてるんです。そのとおりなんです。なんか私のいうことがほとんどなくなってきてるんです。もっと教えてほしいんです。

熊さん：フォーマライズすると、平均$\mu$、分散$\sigma^2$の母集団から得られたサンプルの、（仮想的な）サンプル内平均の確率変数の平均が$\mu$になるということですね、今までの話は。

ご隠居：へーそうなんだ。

熊さん：「そうなんだ」じゃないでしょう。しっかりしてくれよ。ていうかそこは「そうなんです」じゃないのか。

ご隠居：躁なんです? 北杜夫か?

熊さん：ぢゃあ次行くんです。今までの話だと、とりあえず、サンプルを何回もとって、サンプル内平均の平均をとれば母平均は確実に推定できそうだということでしたね。しかし、繰り返しになりますがこれは非現実的な話ですよね。基本的には1回しかサンプルはとれないのだから。となると母平均$\mu$から離れた値がサンプル内平均として出現する可能性も、すごく低いというわけではなさそうです。

ご隠居：安心してください。

熊さん：といいますと。

ご隠居：その心配は、サンプルサイズ$n$を大きくすることで解決できます。

熊さん：たったそれだけで。

ご隠居：といいますのは、仮想的サンプル内平均確率変数の分散は$\frac{\sigma^2}{n}$に一致するからなんです。

熊さん：ちょっとまだ含意をつかみかねているんですが。

ご隠居：要は、サンプルサイズが大きくなるほど仮想的サンプル内平均確率変数の分散は小さくなり、$\mu$近傍の値をとる可能性が高くなる...

熊さん：つまり、一回きりのサンプリングから得られたサンプル内平均でも、$n$が大きければ$\mu$に近い可能性が高く、推定の精度を上げられると...?

ご隠居：そういうことなんです。

熊さん：サンプルサイズの大きさが重要なのねん。

ご隠居：ちなみに上で「仮想的サンプル内平均確率変数」と繰り返し呼んできたのが、標本分布と一般的に呼ばれているものです。とかく数学関連の呼称は直観的にわかりにくくて困るんです。



サンプルサイズ$n$のサンプルをとる作業を（たとえば100回）繰り返し、（その100個の）サンプル内平均をひとつの確率変数とみなすと、$n$が大きくなるほどその確率変数の確率分布が$N(\mu, \sigma^2)$に近づくという定理である。

実際にはサンプルをとる作業は1回しかできないが、サンプルを1回だけとっても、$n$が十分に大きければそのサンプル内平均は母平均$\mu$の付近の値が出る可能性が高い、ということでもある。

サンプルサイズが小さめでも平均的にはサンプル内平均は母平均に一致するが、分散が大きくなるため推定が不正確になるのら。だからある程度サンプルサイズは大きいほうがいいのら。
